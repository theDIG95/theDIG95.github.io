---
title: Performance Gains - Numba
layout: post
icon : fa-code 
---

The rapid development speed using python does not come without it's problems. One of the major issues of being an interpreted language, is the speed. However, there exist many methods that can help increase the speed of the application. One library that provides such functionality is [Numba](http://numba.pydata.org/) It uses just in time compilation to greatly improve the speed over vanilla python. It is directed towards scientific computing so it does not work for all use-cases but sill it's advantages are noteworthy.

## Just in time compilation  

Numba allows for python functions to be compiled just in time, to increase the speed of execution. It works on a few specific object types and compiles them down to machine native code. First we look at an example function we need to speed up.

```python
def calc(x, const):
    return x ** const
```

This is a simple function that raises a number `x` to the power `const`. Now we want it to execute it for a number of inputs we can use a for loop to pass it values and store the results.

```python
import numpy

x = numpy.arange(10000, dtype=numpy.int32)
const = 1.5
ret = numpy.zeros(x.shape, dtype=numpy.float64)
for idx, elem in enumerate(x):
    ret[idx] = calc(elem, const)
```

This approach seems counter intuitive as the same operation can be done on the numpy array. But for any such operations that are not available in high performance libraries such as Numpy and we are forced to call a function many times this method presents us with a speed boost.

Now we can decorate this function to be compiled at runtime by adding a decorator.

```python
from numba import njit int32, float64

@njit(float64(int32, float64))
def calc_jit(x, const):
    return x ** const
```

Here using the `@njit` decorator instead of `@jit` ensures that the compiled code does not fallback to python types. `@njit` is equal to `@jit(nopython = True)`. Additionally we pass the decorator the expected input types so that it does not type cast the inputs incorrectly and cause any additional overhead.

Now we look at the speed advantages. First we define our inputs

```python
x = numpy.arange(10000, dtype=numpy.int32)
const = 1.5
ret = numpy.zeros(x.shape, dtype=numpy.float64
```

Here `ret` is used to store output. Now we time the execution of the functions.

```bash
In [5]: %%timeit
    ...: for idx, elem in enumerate(x):
    ...:     ret[idx] = calc(elem, const)
34.4 ms +- 2.84 ms per loop (mean +- std. dev. of 7 runs, 10 loops each)

In [6]: %%timeit
    ...: for idx, elem in enumerate(x):
    ...:     ret[idx] = calc_jit(elem, const)
6.87 ms +- 86.5 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
```

As we can see the execution times goes down form 34.4 ms to 6.87 ms, a 5 times speed up. This speed-up increases for larger number of inputs and more complex operations than a simple exponential. However as this operations is available in Numpy, it outperforms for this simple operation.

```bash
In [7]: %%timeit
    ...: x ** const
744 us +- 2.46 us per loop (mean +- std. dev. of 7 runs, 1000 loops each)
```

## Vectorize a function  

Rather than just compiling a function we can also vectorize it. That is to say that it would accept an array and process it element-wise. This is done via the `@vectorize` decorator.

```python
@vectorize([float64(int32, float64)])
def calc_vect(x, const):
    return x ** const
```

Now that we time it we see that it's speed is more comparable to Numpy.

```python
In [7]: %%timeit
    ...: ret = calc_vect(x, const)
760 us +- 6.07 us per loop (mean +- std. dev. of 7 runs, 1000 loops each)
```

## Vectorizing for multiple arrays  

Numba also allows for the vecotization of an arbitrary number of arrays with different number of elements i.e. dimensions using the `@guvectorize` decorator. One thing to note about this is that it does not return a value but we can mutate an array and use it as an output.

```python
@guvectorize([(int32[:], float64, float64[:])], '(n),()->(n)')
def calc_gvect(x, const, res):
    for i in range(x.shape[0]):
        res[i] = x[i] ** const
```

Here apart form passing the data types we also pass it the layout `'(n),()->(n)'` which tells it how the input and output are related. It also performs close to Numpy operations.

```bash
In [17]: %%timeit
    ...: ret = numpy.zeros(x.shape, dtype=numpy.float64)
    ...: calc_gvect(x, const, ret)
747 us +- 2.91 us per loop (mean +- std. dev. of 7 runs, 1000 loops each)
```

## Using parallel operations

We can also use the `@jit` `@njit` and `@vectorize` decorators in parallel mode which allows for the computation to be spread out on all of the CPU cores and gives us an additional advantage.

```python
@njit((int32[:], float64, float64[:]), parallel = True)
def parl(x, const, res):
    for i in prange(x.shape[0]):
        res[i] = x[i] ** const
    return res
```

Now we see the real advantage as it starts to outperform Numpy

```bash
In [11]: %%timeit
    ...: ret = numpy.zeros(x.shape, dtype=numpy.float64)
    ...: parl(x, const, ret)
584 us +- 36.2 us per loop (mean +- std. dev. of 7 runs, 1000 loops each)
```

However as with all parallel operations we still need to watch for the overhead and use it for a very large number of inputs otherwise this parallelization becomes a disadvantage.

## Array operations with stencils

Numba also supports stencils that are functions that operate over a single array and mutate the elements via the given function. It can be useful for operations such as filtering or convolution of arrays. We use it to implement a simple moving average filter.

```python
@stencil(neighborhood = ((-30, 0),))
def sten(x):
    mov_avg = 0
    for i in range(-30, 0):
        mov_avg = x[i]
    return mov_avg / 30
```

Here the indexing for the array is relative which is to say that it is calculated with respect to the element that is being operated on. `neighborhood = ((-30, 0),)` here defines the limit of that relative indexing. The returned value is stored in the place of the element it was being operated on. It returns an array the same of the dimension as the input. The border values can be set to a constant, the default value is zero.

## Why use Numba  

As Numba is for scientific computing many of the features are also available in numpy or scipy and for straightforward cases they provide sufficient speed. However there are cases when these features are combined in a more complex form that they lose efficiency. In such cases numba can be a very helpful alternative with relatively straightforward interface so that the development time is not affected either.
