---
title: Optimized Video Game Price Monitor
layout: post
icon : fa-code 
---

We looked at a scraper to monitor video game prices in [this example](https://thedig95.github.io/2018/08/01/games.html). However, any process can be optimized to perform better in terms of speed or resource consumption. In this example we will optimize our game price monitor by using `concurrent.futures` pooling methods.

## Sequential parsing  

In the previous example we fetched each page and parsed it in a sequential manner.

```python
# Read the links
links = read_links()
# Get info for each page
for link in links:
    page_soup = get_link_page(link)
    parse_page_info(page_soup)
```

Here the pages are processed one by one in a single process where time is wasted while waiting for the response of the server. Also, each page is parsed before the next which can be done in separate processes in parallel.

## Getting pages in threads  

We can use a pool of threads to get the pages in parallel. As it is an I/O bound operation i.e. it waits for the response from the server threads are more suited for this kind of operation.

```python
# Get pages in threads
with concurrent.futures.ThreadPoolExecutor() as executer:
    pages = executer.map(
        get_link_page, links
    )
pages = list(page for page in pages)
```

Here we use a default number of workers to get each of the link's pages in parallel.

## Parsing pages in processes  

Now that we have our pages we parse them in separate process as it is a CPU bound process.

```python
# Parse pages in processes
with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executer:
    executer.map(
        parse_page_info, pages
    )
```

This will use a separate process to print out the details of each page.

## Cost of optimization  

The optimization doesn't come without a cost. Where we have gained speed we have consumed more resources.  
In terms of memory usage all the pages are being stored in a single list in `pages = list(page for page in pages)` whereas in the sequential implementation the same variable was being overwritten to store the page.  
In terms of CPU usage now more cores of the CPU are being spent as the pages are being parsed separately in a process. Also, we have the overhead of inter-process communication and the cost of spawning new processes.